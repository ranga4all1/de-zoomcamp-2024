{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb08d90b-3bb7-409a-b4d8-fff22ef1e85d",
   "metadata": {},
   "source": [
    "## Week 5 Homework - batch - Pyspark\n",
    "\n",
    "In this homework we'll put what we learned about Spark in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519b3897-709e-43bc-99a3-53dc82e5db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230f81c1-3c15-4d6e-9613-252ca2c5c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/04 01:29:10 WARN Utils: Your hostname, codespaces-abf587 resolves to a loopback address: 127.0.0.1; using 172.16.5.4 instead (on interface eth0)\n",
      "24/03/04 01:29:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/04 01:29:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3026f0-c5be-474c-af49-23b0fa1babb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/python/3.10.13/lib/python3.10/site-packages/pyspark/__init__.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b68a29-5f4d-45b2-bdf2-17cf751a377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9eef111-8475-4158-93cc-db13b2527713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-04 01:29:12--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 20.29.134.23\n",
      "Connecting to github.com (github.com)|20.29.134.23|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T012733Z&X-Amz-Expires=300&X-Amz-Signature=c7c621f51f3846375678f851d6d37e74af9d2a991efbbf077d79a0f1b6d94e78&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-04 01:29:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T012733Z&X-Amz-Expires=300&X-Amz-Signature=c7c621f51f3846375678f851d6d37e74af9d2a991efbbf077d79a0f1b6d94e78&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  93.9MB/s    in 0.2s    \n",
      "\n",
      "2024-03-04 01:29:13 (93.9 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede7b170-a18a-40d6-9776-4bb9b61eadcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-rw- 1 codespace codespace 19M Dec  2  2022 \u001b[0m\u001b[01;31mfhv_tripdata_2019-10.csv.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls -lh fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66fe81f3-2a3c-43db-b087-92657d444978",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -f fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01bb768f-8947-462d-bf2e-89d515a53b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-rw- 1 codespace codespace 115M Dec  2  2022 fhv_tripdata_2019-10.csv\n"
     ]
    }
   ],
   "source": [
    "ls -lh fhv_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4623c2ea-503d-4864-8be3-10cc49d7be51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897494 fhv_tripdata_2019-10.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhv_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d25e411-882b-4fd3-af03-b1aaeddeef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'n=10' for reading: No such file or directory\n",
      "==> fhv_tripdata_2019-10.csv <==\n",
      "dispatching_base_num,pickup_datetime,dropOff_datetime,PUlocationID,DOlocationID,SR_Flag,Affiliated_base_number\n",
      "B00009,2019-10-01 00:23:00,2019-10-01 00:35:00,264,264,,B00009\n",
      "B00013,2019-10-01 00:11:29,2019-10-01 00:13:22,264,264,,B00013\n",
      "B00014,2019-10-01 00:11:43,2019-10-01 00:37:20,264,264,,B00014\n",
      "B00014,2019-10-01 00:56:29,2019-10-01 00:57:47,264,264,,B00014\n",
      "B00014,2019-10-01 00:23:09,2019-10-01 00:28:27,264,264,,B00014\n",
      "B00021         ,2019-10-01 00:00:48,2019-10-01 00:07:12,129,129,,B00021         \n",
      "B00021         ,2019-10-01 00:47:23,2019-10-01 00:53:25,57,57,,B00021         \n",
      "B00021         ,2019-10-01 00:10:06,2019-10-01 00:19:50,173,173,,B00021         \n",
      "B00021         ,2019-10-01 00:51:37,2019-10-01 01:06:14,226,226,,B00021         \n"
     ]
    }
   ],
   "source": [
    "!head n=10 fhv_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cbade3-c141-401c-b8e7-f7c4c066a45b",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "\n",
    "- FHV October 2019\n",
    "- Read the October 2019 FHV into a Spark Dataframe with a schema as we did in the lessons.\n",
    "- Repartition the Dataframe to 6 partitions and save it to parquet.\n",
    "\n",
    "- What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f1f4a6a-e903-4f7e-bb5d-8919f7596a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6a8958-4fea-4b2b-a440-59cb6feafd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropOff_datetime: string (nullable = true)\n",
      " |-- PUlocationID: string (nullable = true)\n",
      " |-- DOlocationID: string (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "177620a9-12f3-4b94-9e59-5410c5ca3a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb89011f-a9d9-4e9f-b5a2-68fff8a19ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3292a37-0cc1-42f2-8197-3d0244b9e5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/04 01:29:27 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .repartition(6) \\\n",
    "    .write.parquet('fhvhv/2019/10/', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2202e67-de2e-45df-b237-ae55e7597d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhvhv/2019/10/:\n",
      "total 38M\n",
      "-rw-r--r-- 1 codespace codespace    0 Mar  4 01:29 _SUCCESS\n",
      "-rw-r--r-- 1 codespace codespace 6.3M Mar  4 01:29 part-00000-cd3a5aea-cbbf-40e2-b049-1692609f2ee3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 codespace codespace 6.3M Mar  4 01:29 part-00001-cd3a5aea-cbbf-40e2-b049-1692609f2ee3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 codespace codespace 6.3M Mar  4 01:29 part-00002-cd3a5aea-cbbf-40e2-b049-1692609f2ee3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 codespace codespace 6.3M Mar  4 01:29 part-00003-cd3a5aea-cbbf-40e2-b049-1692609f2ee3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 codespace codespace 6.3M Mar  4 01:29 part-00004-cd3a5aea-cbbf-40e2-b049-1692609f2ee3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 codespace codespace 6.3M Mar  4 01:29 part-00005-cd3a5aea-cbbf-40e2-b049-1692609f2ee3-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lhR fhvhv/2019/10/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5fa1-87d2-4651-a1c9-bb94b1712a9a",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "- Count records\n",
    "- How many taxi trips were there on the 15th of October?\n",
    "- Consider only trips that started on the 15th of October."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "507413c5-d678-438f-8914-0a06ec2e57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parquet files\n",
    "df_fhvhv = spark.read.parquet('fhvhv/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4384087-284e-456a-88f8-5f5a9be05d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   NULL|                  NULL|\n",
      "|              B01315|2019-10-05 15:13:04|2019-10-05 15:19:48|         264|          74|   NULL|                B01315|\n",
      "|              B01984|2019-10-12 17:13:00|2019-10-12 17:40:00|         264|          75|   NULL|                B01984|\n",
      "|              B00310|2019-10-15 10:55:04|2019-10-15 11:00:45|         264|         247|   NULL|                B03047|\n",
      "|              B00932|2019-10-08 06:58:42|2019-10-08 07:11:11|         264|          37|   NULL|                B00932|\n",
      "|              B01029|2019-10-10 14:45:00|2019-10-10 15:47:00|         264|         264|   NULL|                B01029|\n",
      "|              B01087|2019-10-14 18:41:24|2019-10-14 19:02:06|         261|         186|   NULL|                B01087|\n",
      "|              B03080|2019-10-05 14:49:10|2019-10-05 15:02:14|         264|          25|   NULL|                B02889|\n",
      "|              B03160|2019-10-10 12:50:00|2019-10-10 13:34:00|          77|          77|   NULL|                B02882|\n",
      "|              B02472|2019-10-16 14:12:36|2019-10-16 14:35:00|         264|         157|   NULL|                B02472|\n",
      "|              B01051|2019-10-05 22:06:46|2019-10-05 22:16:57|         264|         182|   NULL|                B01051|\n",
      "|              B02111|2019-10-08 14:58:52|2019-10-08 15:40:41|          98|          79|   NULL|                B02111|\n",
      "|              B00254|2019-10-03 20:33:11|2019-10-03 21:52:16|         246|         265|   NULL|                B02356|\n",
      "|              B00756|2019-10-16 10:58:00|2019-10-16 11:18:00|         264|         264|   NULL|                B00756|\n",
      "|              B02249|2019-10-04 19:55:49|2019-10-04 20:08:25|         264|         192|   NULL|                B02249|\n",
      "|              B03202|2019-10-13 07:39:33|2019-10-13 08:18:31|         264|         132|   NULL|                B03202|\n",
      "|              B00419|2019-10-11 08:33:12|2019-10-11 08:46:22|         182|         185|   NULL|                B00419|\n",
      "|              B02095|2019-10-09 11:16:00|2019-10-09 11:44:00|         264|         264|   NULL|                B02095|\n",
      "|              B02930|2019-10-05 22:06:15|2019-10-05 22:25:31|         264|          69|   NULL|                B02930|\n",
      "|              B01239|2019-10-07 20:08:15|2019-10-07 20:16:06|         264|          51|   NULL|                B02847|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhvhv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4177f3a4-6722-43b0-a83a-d39029f54607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhvhv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53205e72-59e3-431b-a3bd-24e514b98b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d557838-9be9-4dea-9d8a-4839b20b74c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhvhv \\\n",
    "    .withColumn('pickup_date', F.to_date(df_fhvhv.pickup_datetime)) \\\n",
    "    .filter(\"pickup_date = '2019-10-15'\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5965289-cfae-4c9b-95ee-636e47e03051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|count_trips_oct_15|\n",
      "+------------------+\n",
      "|             62610|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternate way: SQL\n",
    "\n",
    "df_fhvhv.createOrReplaceTempView('fhvhv_2019_10')\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(1) AS count_trips_oct_15\n",
    "FROM \n",
    "    fhvhv_2019_10\n",
    "WHERE\n",
    "    to_date(pickup_datetime) = '2019-10-15';\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab3c1e99-6528-4808-9686-513cd4684a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|to_date(pickup_datetime)|count|\n",
      "+------------------------+-----+\n",
      "|              2019-10-01|59873|\n",
      "|              2019-10-02|68746|\n",
      "|              2019-10-03|71638|\n",
      "|              2019-10-04|68227|\n",
      "|              2019-10-05|52398|\n",
      "|              2019-10-06|45665|\n",
      "|              2019-10-07|66137|\n",
      "|              2019-10-08|64049|\n",
      "|              2019-10-09|60468|\n",
      "|              2019-10-10|68559|\n",
      "|              2019-10-11|67715|\n",
      "|              2019-10-12|51434|\n",
      "|              2019-10-13|45900|\n",
      "|              2019-10-14|52665|\n",
      "|              2019-10-15|62610|\n",
      "|              2019-10-16|68156|\n",
      "|              2019-10-17|67656|\n",
      "|              2019-10-18|68471|\n",
      "|              2019-10-19|52530|\n",
      "|              2019-10-20|48304|\n",
      "+------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Alternate way\n",
    "\n",
    "# Num trips on October 15th\n",
    "df_fhvhv.groupBy(F.to_date('pickup_datetime')).count().orderBy(F.to_date('pickup_datetime')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9a02270-e4c6-4556-bf1a-fb0df3734d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trips_oct_15: 62610\n"
     ]
    }
   ],
   "source": [
    "# Alternate way\n",
    "# Filter the DataFrame for trips on October 15th\n",
    "oct_15_trips = df_fhvhv.filter(F.col('pickup_datetime').cast('date') == '2019-10-15')\n",
    "\n",
    "# Count the number of trips\n",
    "num_trips_oct_15 = oct_15_trips.count()\n",
    "\n",
    "print(f'num_trips_oct_15: {num_trips_oct_15}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc79b7-3544-47e1-94a7-6ce664c9d359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cd9baf2-3448-42fe-af2d-cfe80552e155",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "- Longest trip for each day\n",
    "- What is the length of the longest trip in the dataset in hours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a66d26ea-7195-4e17-913a-bfac93205292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropOff_datetime',\n",
       " 'PUlocationID',\n",
       " 'DOlocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhvhv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6814e81-d3fb-4751-b3d9-acb73f64a9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|pickup_date|     max(duration)|\n",
      "+-----------+------------------+\n",
      "| 2019-10-28|          631152.5|\n",
      "| 2019-10-11|          631152.5|\n",
      "| 2019-10-31| 87672.44083333333|\n",
      "| 2019-10-01| 70128.02805555555|\n",
      "| 2019-10-17|            8794.0|\n",
      "| 2019-10-26| 8784.166666666666|\n",
      "| 2019-10-30|1464.5344444444445|\n",
      "| 2019-10-25|1056.8266666666666|\n",
      "| 2019-10-02| 769.2313888888889|\n",
      "| 2019-10-23| 745.6166666666667|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fhvhv \\\n",
    "    .withColumn('duration', (df_fhvhv.dropOff_datetime.cast('long') - df_fhvhv.pickup_datetime.cast('long')) / 3600) \\\n",
    "    .withColumn('pickup_date', F.to_date(df_fhvhv.pickup_datetime)) \\\n",
    "    .groupBy('pickup_date') \\\n",
    "    .max('duration') \\\n",
    "    .orderBy('max(duration)', ascending=False) \\\n",
    "    .limit(10) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "361012e3-9ad4-4fdc-a775-2dd5311f9562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|pickup_date|duration_hours|\n",
      "+-----------+--------------+\n",
      "| 2019-10-28|      631152.5|\n",
      "| 2019-10-11|      631152.5|\n",
      "| 2019-10-31|      87672.44|\n",
      "| 2019-10-01|      70128.03|\n",
      "| 2019-10-17|        8794.0|\n",
      "| 2019-10-26|       8784.17|\n",
      "| 2019-10-30|       1464.53|\n",
      "| 2019-10-25|       1056.83|\n",
      "| 2019-10-02|        769.23|\n",
      "| 2019-10-23|        745.62|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Alternate way: SQL\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    to_date(pickup_datetime) AS pickup_date,\n",
    "    ROUND(MAX((CAST(dropoff_datetime AS LONG) - CAST(pickup_datetime AS LONG)) / 3600), 2) AS duration_hours\n",
    "FROM \n",
    "    fhvhv_2019_10\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    2 DESC\n",
    "LIMIT 10;\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071129bc-6164-4976-8b32-a7a3998f1c6c",
   "metadata": {},
   "source": [
    "## Question 6:\n",
    "- Least frequent pickup location zone\n",
    "- Load the zone lookup data into a temp view in Spark\n",
    "- Using the zone lookup data and the FHV October 2019 data, what is the name of the LEAST frequent pickup location Zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93c23673-fb73-4bc6-b5e3-133c7f796acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-04 01:29:44--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 20.29.134.23\n",
      "Connecting to github.com (github.com)|20.29.134.23|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T012944Z&X-Amz-Expires=300&X-Amz-Signature=73e8449a1a07d78f88c52e5d552567587fcdf929ed12570258fcb74197d9030a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-04 01:29:44--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T012944Z&X-Amz-Expires=300&X-Amz-Signature=73e8449a1a07d78f88c52e5d552567587fcdf929ed12570258fcb74197d9030a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv.1’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-04 01:29:45 (29.5 MB/s) - ‘taxi_zone_lookup.csv.1’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07d2d876-594e-4c31-8f8a-bece15e9eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-rw- 1 codespace codespace 12322 Jul 19  2022 taxi_zone_lookup.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -lH taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72194ab0-9b1a-42f7-9a23-c8b861184dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'n=10' for reading: No such file or directory\n",
      "==> taxi_zone_lookup.csv <==\n",
      "\"LocationID\",\"Borough\",\"Zone\",\"service_zone\"\n",
      "1,\"EWR\",\"Newark Airport\",\"EWR\"\n",
      "2,\"Queens\",\"Jamaica Bay\",\"Boro Zone\"\n",
      "3,\"Bronx\",\"Allerton/Pelham Gardens\",\"Boro Zone\"\n",
      "4,\"Manhattan\",\"Alphabet City\",\"Yellow Zone\"\n",
      "5,\"Staten Island\",\"Arden Heights\",\"Boro Zone\"\n",
      "6,\"Staten Island\",\"Arrochar/Fort Wadsworth\",\"Boro Zone\"\n",
      "7,\"Queens\",\"Astoria\",\"Boro Zone\"\n",
      "8,\"Queens\",\"Astoria Park\",\"Boro Zone\"\n",
      "9,\"Queens\",\"Auburndale\",\"Boro Zone\"\n"
     ]
    }
   ],
   "source": [
    "!head n=10 taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2bd3e89-7597-462d-b397-e63231c676f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9630e6d8-8f1a-496b-8dbd-0da04f48d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93a562c2-0fcb-4056-9c34-655fe907fb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c389fe38-58ac-4e23-a156-456f19bd0f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones \\\n",
    "    .repartition(1) \\\n",
    "    .write.parquet('zones/', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2befde2f-4b88-429c-a9b3-314db3b54c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zones/:\n",
      "total 8.0K\n",
      "-rw-r--r-- 1 codespace codespace    0 Mar  4 01:29 _SUCCESS\n",
      "-rw-r--r-- 1 codespace codespace 5.8K Mar  4 01:29 part-00000-7807c0c7-c7ce-4da0-9207-e1c274844524-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lhR zones/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e39d7ccc-5e93-4c10-973a-596cb89e0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parquet files\n",
    "df_zones = spark.read.parquet('zones/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61c7dc72-3a60-48ea-8c99-298dad8b2a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0297dfc7-eb3b-4b3d-b0cb-2f122e947c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6585b2ed-53bb-4613-9058-1db790e0a223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropOff_datetime',\n",
       " 'PUlocationID',\n",
       " 'DOlocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhvhv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1188376d-090c-4536-bf44-6742debc15de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LocationID', 'Borough', 'Zone', 'service_zone']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1d151ce-da45-455e-8a2f-820adbb665b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhvhv.createOrReplaceTempView('fhvhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ce0029f-4709-4991-a41a-71c601abdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.createOrReplaceTempView('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa01a3fe-69d2-4ff4-9f81-f4ebe472d99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|            pul_zone|count_pul_zone|\n",
      "+--------------------+--------------+\n",
      "|         Jamaica Bay|             1|\n",
      "|Governor's Island...|             2|\n",
      "| Green-Wood Cemetery|             5|\n",
      "|       Broad Channel|             8|\n",
      "|     Highbridge Park|            14|\n",
      "+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    pul.Zone AS pul_zone,\n",
    "    COUNT(1) AS count_pul_zone\n",
    "FROM \n",
    "    fhvhv AS fhv \n",
    "    LEFT JOIN zones AS pul ON fhv.PULocationID = pul.LocationID\n",
    "    LEFT JOIN zones AS dol ON fhv.DOLocationID = dol.LocationID\n",
    "GROUP BY \n",
    "    1\n",
    "ORDER BY\n",
    "    2\n",
    "LIMIT 5\n",
    ";\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff77efb-3d55-4259-8d2b-607c90c07a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
